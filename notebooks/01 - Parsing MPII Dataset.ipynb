{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center style=\"font-weight:bold;font-size:20px\">wbenbihi/hourglasstensorlfow: Stacked Hourglass Network for Human Pose Estimation</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center style=\"font-weight:bold;font-size:20px\">Parsing MPII Human Pose Dataset</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:32.397981Z",
     "start_time": "2019-11-12T22:43:32.392423Z"
    }
   },
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "sys.path.append(os.path.join('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:33.580567Z",
     "start_time": "2019-11-12T22:43:32.709970Z"
    }
   },
   "outputs": [],
   "source": [
    "# Specific Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from config import CFG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:33.584193Z",
     "start_time": "2019-11-12T22:43:33.581946Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_FOLDER = CFG.ROOT_FOLDER\n",
    "DATA_FOLDER = 'data'\n",
    "MPII_MAT = 'mpii_human_pose_v1_u12_1.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:33.716601Z",
     "start_time": "2019-11-12T22:43:33.713583Z"
    }
   },
   "outputs": [],
   "source": [
    "MAT_PATH = os.path.join(ROOT_FOLDER, DATA_FOLDER, MPII_MAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:34.529365Z",
     "start_time": "2019-11-12T22:43:34.508191Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_point(point):\n",
    "    return {\n",
    "        'point':{\n",
    "            'x':point.__dict__.get('x')[0][0] if ('x' in point.__dict__) and (0 not in point.__dict__.get('x').shape) else None,\n",
    "            'y':point.__dict__.get('y')[0][0] if ('y' in point.__dict__) and (0 not in point.__dict__.get('y').shape) else None,\n",
    "            'id':point.__dict__.get('id')[0][0] if ('id' in point.__dict__) and (0 not in point.__dict__.get('id').shape) else None,\n",
    "            'is_visible':point.__dict__.get('is_visible')[0][0] if ('is_visible' in point.__dict__) and (0 not in point.__dict__.get('is_visible').shape)  else None,\n",
    "        }\n",
    "    }\n",
    "\n",
    "def parse_person(person, idx):\n",
    "    return {\n",
    "        'person':{\n",
    "            'ridx':idx,\n",
    "            'x1':person.__dict__.get('x1')[0][0] if 'x1' in (person.__dict__) and (0 not in person.__dict__.get('x1').shape) else None,\n",
    "            'x2':person.__dict__.get('x2')[0][0] if 'x2' in (person.__dict__) and (0 not in person.__dict__.get('x2').shape) else None,\n",
    "            'y1':person.__dict__.get('y1')[0][0] if 'y1' in (person.__dict__) and (0 not in person.__dict__.get('y1').shape) else None,\n",
    "            'y2':person.__dict__.get('y2')[0][0] if 'y2' in (person.__dict__) and (0 not in person.__dict__.get('y2').shape) else None,\n",
    "            'scale':person.__dict__.get('scale')[0][0] if 'scale' in (person.__dict__) and (0 not in person.__dict__.get('scale').shape) else None,\n",
    "            'objpos':{\n",
    "                'x':person.__dict__.get('objpos')[0][0].__dict__.get('x')[0][0] if ('objpos' in person.__dict__) and (0 not in person.__dict__.get('objpos').shape) else None,\n",
    "                'y':person.__dict__.get('objpos')[0][0].__dict__.get('y')[0][0] if ('objpos' in person.__dict__) and (0 not in person.__dict__.get('objpos').shape) else None,\n",
    "            },\n",
    "            'points':[\n",
    "                parse_point(point) for point in person.__dict__.get('annopoints')[0][0].__dict__['point'][0]\n",
    "            ] if 'annopoints' in (person.__dict__) and (0 not in person.__dict__.get('annopoints').shape) else None,\n",
    "        }\n",
    "    }\n",
    "\n",
    "def parse_persons(persons):\n",
    "    return [\n",
    "        parse_person(person, i)\n",
    "        for i, person in enumerate(persons)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T23:28:05.593768Z",
     "start_time": "2019-11-12T23:28:05.579308Z"
    }
   },
   "outputs": [],
   "source": [
    "def cast_iterable(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k:cast_iterable(v) for k,v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [cast_iterable(k) for k in obj]\n",
    "    elif obj is None:\n",
    "        return obj\n",
    "    elif isinstance(obj, int) or np.issubdtype(type(obj), np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, float) or np.issubdtype(type(obj), np.float):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, str):\n",
    "        return obj\n",
    "    else:\n",
    "        raise TypeError(f'{obj} is typed {type(obj)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPII Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------- \n",
    "MPII Human Pose Dataset, Version 1.0 \n",
    "\n",
    "Copyright 2015 Max Planck Institute for Informatics \n",
    "\n",
    "Licensed under the Simplified BSD License [see bsd.txt] \n",
    "\n",
    "--------------------------------------------------------------------------- \n",
    "\n",
    "We are making the annotations and the corresponding code freely available for research \n",
    "purposes. If you would like to use the dataset for any other purposes please contact \n",
    "the authors. \n",
    "\n",
    "## Introduction\n",
    "MPII Human Pose dataset is a state of the art benchmark for evaluation\n",
    "of articulated human pose estimation. The dataset includes around\n",
    "**25K images** containing over **40K people** with annotated body\n",
    "joints. The images were systematically collected using an established\n",
    "taxonomy of every day human activities. Overall the dataset covers\n",
    "**410 human activities** and each image assigned an activity\n",
    "label. Each image was extracted from a YouTube video and provided with\n",
    "preceding and following un-annotated frames. In addition, for the test\n",
    "set we obtained richer annotations including body part occlusions and\n",
    "3D torso and head orientations.\n",
    "\n",
    "Following the best practices for the performance evaluation benchmarks\n",
    "in the literature we withhold the test annotations to prevent\n",
    "overfitting and tuning on the test set. We are working on an automatic\n",
    "evaluation server and performance analysis tools based on rich test\n",
    "set annotations.\n",
    "\n",
    "## Citing the dataset\n",
    "```\n",
    "@inproceedings{andriluka14cvpr,\n",
    "               author = {Mykhaylo Andriluka and Leonid Pishchulin and Peter Gehler and Schiele, Bernt}\n",
    "               title = {2D Human Pose Estimation: New Benchmark and State of the Art Analysis},\n",
    "               booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n",
    "               year = {2014},\n",
    "               month = {June}\n",
    "}\n",
    "```\n",
    "\n",
    "## Download\n",
    "\n",
    "-. **Images (12.9 GB)**\n",
    "   \n",
    "   http://datasets.d2.mpi-inf.mpg.de/andriluka14cvpr/mpii_human_pose_v1.tar.gz\n",
    "-. **Annotations (12.5 MB)**\t\n",
    "   \n",
    "   http://datasets.d2.mpi-inf.mpg.de/andriluka14cvpr/mpii_human_pose_v1_u12.tar.gz\n",
    "-. **Videos for each image (25 batches x 17 GB)**\t\n",
    "\n",
    "   http://datasets.d2.mpi-inf.mpg.de/andriluka14cvpr/mpii_human_pose_v1_sequences_batch1.tar.gz\n",
    "   ...\n",
    "   http://datasets.d2.mpi-inf.mpg.de/andriluka14cvpr/mpii_human_pose_v1_sequences_batch25.tar.gz\n",
    "-. **Image - video mapping (239 KB)**\t\n",
    "   \n",
    "   http://datasets.d2.mpi-inf.mpg.de/andriluka14cvpr/mpii_human_pose_v1_sequences_keyframes.mat\n",
    "\n",
    "## Annotation description \n",
    "Annotations are stored in a matlab structure `RELEASE` having following fields\n",
    "\n",
    "- `.annolist(imgidx)` - annotations for image `imgidx`\n",
    "  - `.image.name` - image filename\n",
    "  - `.annorect(ridx)` - body annotations for a person `ridx`\n",
    "      - `.x1, .y1, .x2, .y2` - coordinates of the head rectangle\n",
    "      - `.scale` - person scale w.r.t. 200 px height\n",
    "      - `.objpos` - rough human position in the image\n",
    "      - `.annopoints.point` - person-centric body joint annotations\n",
    "        - `.x, .y` - coordinates of a joint\n",
    "        - `id` \n",
    "            - joint id [//]: # \"(0 - r ankle, 1 - r knee, 2 - r hip, 3 - l hip, 4 - l knee, 5 - l ankle, 6 - pelvis, 7 - thorax, 8 - upper neck, 9 - head top, 10 - r wrist, 10 - r wrist, 12 - r shoulder, 13 - l shoulder, 14 - l elbow, 15 - l wrist)\"\n",
    "        - `is_visible` - joint visibility\n",
    "  - `.vidx` - video index in `video_list`\n",
    "  - `.frame_sec` - image position in video, in seconds\n",
    " \n",
    "- `img_train(imgidx)` - training/testing image assignment \n",
    "- `single_person(imgidx)` - contains rectangle id `ridx` of *sufficiently separated* individuals\n",
    "- `act(imgidx)` - activity/category label for image `imgidx`\n",
    "  - `act_name` - activity name\n",
    "  - `cat_name` - category name\n",
    "  - `act_id` - activity id\n",
    "- `video_list(videoidx)` - specifies video id as is provided by YouTube. To watch video on youtube go to https://www.youtube.com/watch?v=video_list(videoidx) \n",
    "\n",
    "## Browsing the dataset\n",
    "- Please use our online tool for browsing the data\n",
    "http://human-pose.mpi-inf.mpg.de/#dataset\n",
    "- Red rectangles mark testing images\n",
    "\n",
    "## References\n",
    "- **2D Human Pose Estimation: New Benchmark and State of the Art Analysis.**\n",
    "\n",
    "  Mykhaylo Andriluka, Leonid Pishchulin, Peter Gehler and Bernt Schiele. \n",
    "\n",
    "  IEEE CVPR'14\n",
    "- **Fine-grained Activity Recognition with Holistic and Pose based Features.**\n",
    "\n",
    "  Leonid Pishchulin, Mykhaylo Andriluka and Bernt Schiele.\n",
    "\n",
    "  GCPR'14\n",
    "\n",
    "## Contact\n",
    "You can reach us via `<lastname>@mpi-inf.mpg.de`\n",
    "We are looking forward to your feedback. If you have any questions related to the dataset please let us know.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since MPII Human Pose Dataset labels are recorded in a MATLAB .mat file, we need to parse it to a clean pandas DataFrame. This format is heavily nested and needs a little bit of exploration to parse it completely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:47.671561Z",
     "start_time": "2019-11-12T22:43:36.252759Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load .mat file\n",
    "mat = scipy.io.loadmat(MAT_PATH, struct_as_record=False)\n",
    "release_mat = mat['RELEASE'][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if the `fieldnames` are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:47.678106Z",
     "start_time": "2019-11-12T22:43:47.673764Z"
    }
   },
   "outputs": [],
   "source": [
    "release_mat._fieldnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:47.685309Z",
     "start_time": "2019-11-12T22:43:47.679707Z"
    }
   },
   "outputs": [],
   "source": [
    "# Accessing coordinates X of Point 0 from Person 0 in Image 4\n",
    "release_mat.__dict__['annolist'][0][4].__dict__['annorect'][0][0].__dict__['annopoints'][0][0].__dict__['point'][0][0].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:47.689560Z",
     "start_time": "2019-11-12T22:43:47.687318Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train/Test Label\n",
    "img_train = release_mat.__dict__.get('img_train')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:47.697363Z",
     "start_time": "2019-11-12T22:43:47.690907Z"
    }
   },
   "outputs": [],
   "source": [
    "# List of Videos\n",
    "video_list = release_mat.__dict__.get('video_list')[0]\n",
    "video_list_json = [{'video': {'videoidx':i, 'video_list':item[0]}} for i, item in enumerate(video_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:47.701853Z",
     "start_time": "2019-11-12T22:43:47.698671Z"
    }
   },
   "outputs": [],
   "source": [
    "mpii_version = release_mat.__dict__.get('version')[0]\n",
    "annolist = release_mat.__dict__.get('annolist')[0]\n",
    "single_person = release_mat.__dict__.get('single_person')\n",
    "act = release_mat.__dict__.get('act')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:47.706018Z",
     "start_time": "2019-11-12T22:43:47.703038Z"
    }
   },
   "outputs": [],
   "source": [
    "len(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:47.711817Z",
     "start_time": "2019-11-12T22:43:47.708132Z"
    }
   },
   "outputs": [],
   "source": [
    "act[4][0]._fieldnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:47.814033Z",
     "start_time": "2019-11-12T22:43:47.713768Z"
    }
   },
   "outputs": [],
   "source": [
    "act_json = [\n",
    "    {\n",
    "        'act':{\n",
    "            'imgidx':i,\n",
    "            'cat_name':elem[0].__dict__.get('cat_name')[0] if len(elem[0].__dict__.get('cat_name')) else None,\n",
    "            'act_name':elem[0].__dict__.get('act_name')[0].split(', ') if len(elem[0].__dict__.get('act_name')) else None,\n",
    "            'act_id':elem[0].__dict__.get('act_id')[0][0]\n",
    "        }\n",
    "    } \n",
    "    for i, elem in enumerate(act)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle single_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:47.819216Z",
     "start_time": "2019-11-12T22:43:47.815669Z"
    }
   },
   "outputs": [],
   "source": [
    "len(single_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:47.885533Z",
     "start_time": "2019-11-12T22:43:47.820518Z"
    }
   },
   "outputs": [],
   "source": [
    "single_person_json = [\n",
    "    {\n",
    "        'single_person':{\n",
    "            'imgidx':i,\n",
    "            'ridx': [elm[0] for elm in item[0]] if 0 not in item[0].shape else None\n",
    "        }\n",
    "    }\n",
    "    for i, item in enumerate(single_person)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Annopoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:47.890979Z",
     "start_time": "2019-11-12T22:43:47.887159Z"
    }
   },
   "outputs": [],
   "source": [
    "annolist[0]._fieldnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:48.003616Z",
     "start_time": "2019-11-12T22:43:47.892503Z"
    }
   },
   "outputs": [],
   "source": [
    "annolist_parse_head = [\n",
    "    {\n",
    "        'annopoint':{\n",
    "            'imgidx':i,\n",
    "            'image':item.__dict__.get('image')[0][0].__dict__.get('name')[0],\n",
    "            'annorect':item.__dict__.get('annorect'),\n",
    "            'frame_sec':item.__dict__.get('frame_sec')[0] if 0 not in item.__dict__.get('frame_sec').shape else None,\n",
    "            'vididx':item.__dict__.get('vididx')[0][0] if 0 not in item.__dict__.get('vididx').shape else None,\n",
    "        }\n",
    "    }\n",
    "    for i, item in enumerate(annolist)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:48.009428Z",
     "start_time": "2019-11-12T22:43:48.005094Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sample with raw parsing\n",
    "annolist_parse_head[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:48.014506Z",
     "start_time": "2019-11-12T22:43:48.010900Z"
    }
   },
   "outputs": [],
   "source": [
    "IDX = 4\n",
    "annolist_parse_head[IDX]['annopoint']['annorect'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:48.019481Z",
     "start_time": "2019-11-12T22:43:48.015794Z"
    }
   },
   "outputs": [],
   "source": [
    "IDPERS = 1\n",
    "annolist_parse_head[IDX]['annopoint']['annorect'][0][IDPERS]._fieldnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:48.027368Z",
     "start_time": "2019-11-12T22:43:48.020902Z"
    }
   },
   "outputs": [],
   "source": [
    "(annolist_parse_head[IDX]['annopoint']['annorect'][0][IDPERS].__dict__.get('x1')[0][0],\n",
    "annolist_parse_head[IDX]['annopoint']['annorect'][0][IDPERS].__dict__.get('x2')[0][0],\n",
    "annolist_parse_head[IDX]['annopoint']['annorect'][0][IDPERS].__dict__.get('y1')[0][0],\n",
    "annolist_parse_head[IDX]['annopoint']['annorect'][0][IDPERS].__dict__.get('y2')[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:48.033048Z",
     "start_time": "2019-11-12T22:43:48.029149Z"
    }
   },
   "outputs": [],
   "source": [
    "annolist_parse_head[IDX]['annopoint']['annorect'][0][IDPERS].__dict__.get('scale')[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:48.039681Z",
     "start_time": "2019-11-12T22:43:48.034335Z"
    }
   },
   "outputs": [],
   "source": [
    "(annolist_parse_head[IDX]['annopoint']['annorect'][0][IDPERS].__dict__.get('objpos')[0][0].__dict__.get('x')[0][0],\n",
    "annolist_parse_head[IDX]['annopoint']['annorect'][0][IDPERS].__dict__.get('objpos')[0][0].__dict__.get('y')[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:48.045100Z",
     "start_time": "2019-11-12T22:43:48.040929Z"
    }
   },
   "outputs": [],
   "source": [
    "annolist_parse_head[IDX]['annopoint']['annorect'][0][IDPERS].__dict__.get('annopoints')[0][0].__dict__['point'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:48.050651Z",
     "start_time": "2019-11-12T22:43:48.046306Z"
    }
   },
   "outputs": [],
   "source": [
    "annolist_parse_head[IDX]['annopoint']['annorect'][0][IDPERS].__dict__.get('annopoints')[0][0].__dict__['point'][0][0]._fieldnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:48.063095Z",
     "start_time": "2019-11-12T22:43:48.052433Z"
    }
   },
   "outputs": [],
   "source": [
    "(annolist_parse_head[IDX]['annopoint']['annorect'][0][IDPERS].__dict__.get('annopoints')[0][0].__dict__['point'][0][0].__dict__.get('x')[0][0],\n",
    "annolist_parse_head[IDX]['annopoint']['annorect'][0][IDPERS].__dict__.get('annopoints')[0][0].__dict__['point'][0][0].__dict__.get('y')[0][0],\n",
    "annolist_parse_head[IDX]['annopoint']['annorect'][0][IDPERS].__dict__.get('annopoints')[0][0].__dict__['point'][0][0].__dict__.get('id')[0][0],\n",
    "annolist_parse_head[IDX]['annopoint']['annorect'][0][IDPERS].__dict__.get('annopoints')[0][0].__dict__['point'][0][0].__dict__.get('is_visible')[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:16:37.817183Z",
     "start_time": "2019-11-12T22:16:37.808111Z"
    }
   },
   "source": [
    "### Coarse Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:43:50.728583Z",
     "start_time": "2019-11-12T22:43:48.066282Z"
    }
   },
   "outputs": [],
   "source": [
    "annolist_parsed = [\n",
    "    {\n",
    "        'annopoint':{\n",
    "            'imgidx':i,\n",
    "            'image':item.__dict__.get('image')[0][0].__dict__.get('name')[0],\n",
    "            'annorect':parse_persons(item.__dict__.get('annorect')[0]) if 0 not in item.__dict__.get('annorect').shape else None,\n",
    "            'frame_sec':item.__dict__.get('frame_sec')[0][0] if 0 not in item.__dict__.get('frame_sec').shape else None,\n",
    "            'vididx':item.__dict__.get('vididx')[0][0] if 0 not in item.__dict__.get('vididx').shape else None,\n",
    "        }\n",
    "    }\n",
    "    for i, item in enumerate(annolist)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T22:42:57.069525Z",
     "start_time": "2019-11-12T22:42:57.032121Z"
    }
   },
   "source": [
    "## To JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T23:29:23.210052Z",
     "start_time": "2019-11-12T23:29:11.988041Z"
    }
   },
   "outputs": [],
   "source": [
    "json_to_save = [\n",
    "    (cast_iterable(annolist_parsed), 'annolist.json'),\n",
    "    (cast_iterable(single_person_json), 'single_person.json'),\n",
    "    (cast_iterable(video_list_json), 'video_list.json'),\n",
    "    (cast_iterable(act_json), 'act.json'),\n",
    "    (cast_iterable(img_train.tolist()), 'img_train.json'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T23:29:36.317112Z",
     "start_time": "2019-11-12T23:29:27.648145Z"
    }
   },
   "outputs": [],
   "source": [
    "for d, p in json_to_save:\n",
    "    with open(os.path.join(ROOT_FOLDER,DATA_FOLDER, p), 'w') as f:\n",
    "        json.dump(d, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
